/*
* Rendering Shader | Marko Sterbentz, summer 2018
* Contains the methods and kernels needed for using ray marching in combination 
* with raw or HZ-ordered data to produce an accurate and high quality volume visualization.
*/

#pragma kernel CSMain

/*********************************************
*					Structs
**********************************************/
struct MetaBrick
{
	float3 position;
	int size;
	int bufferOffset;
	int bufferIndex;
	int maxZLevel;
	int currentZLevel;
	int id;
	float3 boxMin;
	float3 boxMax;
	uint lastBitMask;
};

struct MetaVolume
{
	float3 position;
	float3 boxMin;
	float3 boxMax;
	float3 scale;
	int numBricks;
	int isHz;
	int numBits;
	int maxGlobalSize;
};

struct Ray
{
	float3 origin;//The origin of the ray. 
	float3 direction;
};

struct BrickIntersection
{
	int id;
	float tNear;
	float tFar;
};

/*********************************************
*			   Variables from C#
**********************************************/
RWTexture2D<float4> Result;
float4x4 _CameraToWorld;//When does this become initialized?
float4x4 _CameraInverseProjection;
RWStructuredBuffer<MetaBrick> _MetaBrickBuffer;
RWStructuredBuffer<MetaVolume> _MetaVolumeBuffer;//This volume buffer seems to only ever hold a single volume. Must volumes be passed via buffers? Why not just make this a metavolume object?
//Essentially, what is the point of wrapping this MetaVolume in a buffer? I guess that all data passed to the shader needs to be wrapped in a buffer perhaps. 
RWStructuredBuffer<uint> _DataBufferZero;
RWStructuredBuffer<uint> _DataBufferOne;
RWStructuredBuffer<uint> _DataBufferTwo;
int _Steps;
float _NormPerRay;
Texture2D<float4> _TransferFunctionTexture;
SamplerState sampler_TransferFunctionTexture;

/*********************************************
*	Newly Defined Variables and Constants
**********************************************/
const static int MAX_BRICKS = 20;	// Note: Making this too large decreases performance

const static uint MASKS_8BIT[] = {0xFF000000, 0x00FF0000, 0x0000FF00, 0x000000FF};
const static int BYTE_SHIFTS_8BIT[] = { 24, 16, 8, 0 };

const static uint MASKS_16BIT[] = {0xFFFF0000, 0x0000FFFF};
const static int BYTE_SHIFTS_16BIT[] = { 16, 0 };

/*********************************************
*			   Ray Init Functions
**********************************************/
/*
 * Create Ray | Marko Sterbentz, summer 2018 
 * "Constructor" for creating a ray struct.
 */
Ray createRay(float3 origin, float3 direction)
{
	Ray ray;
	ray.origin = origin;
	ray.direction = direction;
	return ray;
}

/*
 * Create Camera Ray | Marko Sterbentz, summer 2018
 * Creates a ray struct representing the camera ray for the given pixel uv.
 */
Ray createCameraRay(float2 uv)
{
	// Transform the camera origin to world space
	float3 origin = mul(_CameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;// mul(A,B) does A %*% B as matrices. (%*% meaning 'matrix multiplication'). 
	// If either of the arguments are vectors, they are treated as a row (first arg) or column (second arg) vector ands multiplied accordingly. 
	// Here _CameraToWorld (and _CameraInverseProjection) are 4 by 4 matrices. 

	// Invert the perspective projection of the view-space position
	float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;

	// Transform the direction from camera to world space and normalize
	direction = mul(_CameraToWorld, float4(direction, 0.0f)).xyz;
	direction = normalize(direction);

	return createRay(origin, direction);
}

/*********************************************
*			 Intersection function(s)
**********************************************/
/*
 * Intersect Box | Marko Sterbentz, summer 2017
 * Calculates intersection between a ray and an axis aligned bounding box.
 */
bool IntersectBox(float3 ray_o, float3 ray_d, float3 boxMin, float3 boxMax, out float tNear, out float tFar)
{
	// Compute intersection of ray with all six bbox planes
	float3 invR = 1.0 / ray_d;
	float3 tBot = invR * (boxMin.xyz - ray_o);
	float3 tTop = invR * (boxMax.xyz - ray_o);

	// Re-order intersections to find smallest and largest on each axis
	float3 tMin = min(tTop, tBot);
	float3 tMax = max(tTop, tBot);

	// Find the largest tMin and the smallest tMax
	float2 t0 = max(tMin.xx, tMin.yz);
	float largest_tMin = max(t0.x, t0.y);
	t0 = min(tMax.xx, tMax.yz);
	float smallest_tMax = min(t0.x, t0.y);

	// Check for hit
	bool hit = (largest_tMin <= smallest_tMax);
	tNear = largest_tMin;
	tFar = smallest_tMax;
	return hit;
}

/*********************************************
*			  HZ Curving Functions
**********************************************/
/*
 * Part 1 by 2 | Marko Sterbentz, summer 2017
 * Expands an 8-bit integer into 24 bits by inserting 2 zeros after each bit
 * Taken from: https://webcache.googleusercontent.com/search?q=cache:699-OSphYRkJ:https://fgiesen.wordpress.com/2009/12/13/decoding-morton-codes/+&cd=1&hl=en&ct=clnk&gl=us
 */
uint Part1By2(uint x)
{
	x &= 0x000003ff;                  // x = ---- ---- ---- ---- ---- --98 7654 3210
	x = (x ^ (x << 16)) & 0xff0000ff; // x = ---- --98 ---- ---- ---- ---- 7654 3210
	x = (x ^ (x << 8)) & 0x0300f00f;  // x = ---- --98 ---- ---- 7654 ---- ---- 3210
	x = (x ^ (x << 4)) & 0x030c30c3;  // x = ---- --98 ---- 76-- --54 ---- 32-- --10
	x = (x ^ (x << 2)) & 0x09249249;  // x = ---- 9--8 --7- -6-- 5--4 --3- -2-- 1--0
	return x;
}

/*
 * Morton 3D | Marko Sterbentz, summer 2017
 * Calculates a 24-bit Morton code for the given 3D point located within the unit cube [0, 1]
 * Taken from: https://devblogs.nvidia.com/parallelforall/thinking-parallel-part-iii-tree-construction-gpu/
 */ 
uint morton3D(float3 pos, int brickSize)
{
	// Quantize to the correct resolution
	pos.x = min(max(pos.x * (float)brickSize, 0.0f), (float)brickSize - 1);
	pos.y = min(max(pos.y * (float)brickSize, 0.0f), (float)brickSize - 1);
	pos.z = min(max(pos.z * (float)brickSize, 0.0f), (float)brickSize - 1);

	// Interlace the bits
	uint xx = Part1By2((uint) pos.x);
	uint yy = Part1By2((uint) pos.y);
	uint zz = Part1By2((uint) pos.z);

	return zz << 2 | yy << 1 | xx;
}

/*
 * Compute Masked Z Index | Marko Sterbentz, summer 2017
 * Returns the masked z index, allowing for the the data to be quantized to a level of detail specified by the _CurrentZLevel.
 */
uint computeMaskedZIndex(uint zIndex, int currentZLevel, int maxZLevel)
{
	int zBits = maxZLevel * 3;
	uint zMask = -1 >> (zBits - 3 * currentZLevel) << (zBits - 3 * currentZLevel);
	return zIndex & zMask;
}

/*
 * Get HZ Index | Marko Sterbentz, summer 2017
 * Return the index into the hz-ordered array of data given a quantized point within the volume
 */
uint getHZIndex(uint zIndex, uint lastBitMask)
{
	uint hzIndex = (zIndex | lastBitMask);		// set leftmost one
	hzIndex /= hzIndex & -hzIndex;				// remove trailing zeros
	return (hzIndex >> 1);						// remove rightmost one
}

/*********************************************
*		  Intensity Sampling Functions
**********************************************/
/*
 * Sample Packed Buffers | Marko Sterbentz, summer 2018
 * Samples 8-bit data from a buffer of byte-packed 32-bit uints
 * Param: bufferIndex = the index of the buffer to sample from
 * Param: bufferOffset = the starting position of the data in the buffer
 * Param: byteIndex = the index of the byte in the uint
 */
float samplePackedBuffers(uint bufferIndex, uint bufferOffset, uint byteIndex, int bitsPerPixel)
{
	uint uintIndex;
	uint uintIndexOffset;
	if (bitsPerPixel == 8)
	{
		uintIndex = bufferOffset + (byteIndex / 4);
		uintIndexOffset = byteIndex % 4;

		if (bufferIndex == 0)
		{
			return (_DataBufferZero[uintIndex] & MASKS_8BIT[uintIndexOffset]) >> BYTE_SHIFTS_8BIT[uintIndexOffset];
		}
		else if (bufferIndex == 1)
		{
			return (_DataBufferOne[uintIndex] & MASKS_8BIT[uintIndexOffset]) >> BYTE_SHIFTS_8BIT[uintIndexOffset];
		}
		else if (bufferIndex == 2)
		{
			return (_DataBufferTwo[uintIndex] & MASKS_8BIT[uintIndexOffset]) >> BYTE_SHIFTS_8BIT[uintIndexOffset];
		}
		else
		{
			return 0;
		}
	}
	else
	{
		uintIndex = bufferOffset + (byteIndex / 2);
		uintIndexOffset = byteIndex % 2;

		if (bufferIndex == 0)
		{
			return (_DataBufferZero[uintIndex] & MASKS_16BIT[uintIndexOffset]) >> BYTE_SHIFTS_16BIT[uintIndexOffset];
		}
		else if (bufferIndex == 1)
		{
			return (_DataBufferOne[uintIndex] & MASKS_16BIT[uintIndexOffset]) >> BYTE_SHIFTS_16BIT[uintIndexOffset];
		}
		else if (bufferIndex == 2)
		{
			return (_DataBufferTwo[uintIndex] & MASKS_16BIT[uintIndexOffset]) >> BYTE_SHIFTS_16BIT[uintIndexOffset];
		}
		else
		{
			return 0;
		}
	}
}

/*
 * Sample Intensity Raw | Marko Sterbentz, summer 2018
 * Samples from the data buffer as if it were filled with raw ordered data.
 * Formula: x + (y * width) + (z * width * height)
 * Note: pos is assumed to in local brick space
 */
float sampleIntensityRaw(float3 pos, MetaBrick brick, int bitsPerPixel)
{
	// Convert from texture coordinates to 3d cartesian
	uint x = floor(lerp(0, brick.size - 1, pos.x));
	uint y = floor(lerp(0, brick.size - 1, pos.y));
	uint z = floor(lerp(0, brick.size - 1, pos.z));
	uint index = (x + brick.size * (y + (z * brick.size)));

	// Sample from the byte packed uint buffers
	return samplePackedBuffers(brick.bufferIndex, brick.bufferOffset, index, bitsPerPixel);
}

/*
 * Sample Intensity HZ | Marko Sterbentz, summer 2018
 * Samples from the data buffer as if it were filled with HZ ordered data.
 */
float sampleIntensityHz(float3 pos, MetaBrick brick, int bitsPerPixel)
{
	uint zIndex = morton3D(pos, brick.size);												// Get the Z order index		
	uint maskedZIndex = computeMaskedZIndex(zIndex, brick.currentZLevel, brick.maxZLevel);	// Get the masked Z index
	uint hzIndex = getHZIndex(maskedZIndex, brick.lastBitMask);								// Find the hz order index

	//hzIndex = 8;

	return samplePackedBuffers(brick.bufferIndex, brick.bufferOffset, hzIndex, bitsPerPixel);
}

/*
 * Sample Intensity | Marko Sterbentz, summer 2018
 * Wrapper function for sampling from different types of data volumes (.raw or .hz)
 */
float sampleIntensity(float3 pos, MetaBrick brick, bool isHz, int bitsPerPixel)
{
	// Transform pos from world space to local brick space
	pos = (pos - brick.boxMin) * (_MetaVolumeBuffer[0].maxGlobalSize / brick.size);

	if (isHz)
		return sampleIntensityHz(pos, brick, bitsPerPixel);
	else
		return sampleIntensityRaw(pos, brick, bitsPerPixel);
}

/*********************************************
*	  Transfer Function Sampling Function(s)
**********************************************/
/* 
 * Sample Transfer Function | Marko Sterbentz, summer 2018
 * Maps the given isovalue to the corresponding RGBA color value specified by the transfer function texture provided to the shader.
 */
float4 sampleTransferFunction(float isovalue, int bitsPerPixel)
{
	if (bitsPerPixel == 8)
	{
		return _TransferFunctionTexture.SampleLevel(sampler_TransferFunctionTexture, float2(isovalue / 255, 0.0), 0.0);
	}
	else
	{
		float sampX = isovalue % 256;
		float sampY = isovalue / 256.0f;
		return _TransferFunctionTexture.SampleLevel(sampler_TransferFunctionTexture, float2(sampX, sampY), 0.0);
	}
}


/*********************************************
*		      Sorting Function(s)
**********************************************/
/* 
 * Insertion Sort | Marko Sterbentz, summer 2018
 * Uses the interstion sort algorithm to sort the given array of intersection data
 * This insertion sort matches with what is given on Wikipedia. 
 */
void insertionSort(inout BrickIntersection a[MAX_BRICKS], int length)
{
	int i, j;
	BrickIntersection value;
	for (i = 1; i < length ; i++)
	{
		value = a[i];

		for (j = i-1; j >= 0 && a[j].tNear > value.tNear; j--)
		{
			a[j + 1] = a[j];
		}
			
		a[j + 1] = value;
	}
}

/*********************************************
*			  Rendering Kernel
**********************************************/
[numthreads(32, 32, 1)]
void CSMain(uint3 id : SV_DispatchThreadID)
{
	// Get the dimensions of the RenderTexture
	uint width, height;
	Result.GetDimensions(width, height);

	// Transform pixel to [-1,1] range
	float2 uv = float2(((id.xy + float2(0.5f, 0.5f)) / float2(width, height)) * 2.0f - 1.0f);

	Result[id.xy] = float4(0, 0, 0, 1);

	// Get a ray for the UVs
	Ray ray = createCameraRay(uv);

	// Calculate eye ray intersection with cube bounding box
	float3 boxMin = _MetaVolumeBuffer[0].boxMin;
	
	float3 boxMax = _MetaVolumeBuffer[0].boxMax ;

	float volume_tNear, volume_tFar;
	bool hit = IntersectBox(ray.origin, ray.direction, boxMin, boxMax, volume_tNear, volume_tFar);

	// If there was no intersection with the volume, color the pixel black and do nothing
	if (!hit)
	{
		Result[id.xy] = float4(0, 0, 0, 0);
		return;
	}

	// Check intersections with all each of the bricks
	BrickIntersection intersections[MAX_BRICKS];//An array of BrickIntersection objects defined in the struct above.  

	int numIntersections = 0;
	
	for (int i = 0; i < _MetaVolumeBuffer[0].numBricks; i++)
	{
		BrickIntersection newIntersection; //Is the tNear value or the tFar value ever set for this intersection?
		//We use the newIntersection.tNear and newIntersection.tFar values directly below. But as far as I can tell, they are never set. 
		//Okay, the newIntersection.tNear and newIntersection.tFar are indeed set in the IntersectBox() function.
		//We pass in two parmeters (newIntersection.tNear, newIntersection.tFar) and the function outputs the associated values to those input variables. 
		//You essentially hand in to the function the variable you want to set (in our case, we are handing in newIntersection.tNear, newIntersection.tFar to IntersectionBox()).
		//these values are then set internally by the function. So indeed newIntersection.tFar and newIntersection.tNear are being set. 

		if (IntersectBox(ray.origin, ray.direction, _MetaBrickBuffer[i].boxMin, _MetaBrickBuffer[i].boxMax, newIntersection.tNear, newIntersection.tFar))
		{
			newIntersection.id = _MetaBrickBuffer[i].id;
			intersections[numIntersections] = newIntersection;//This is packing the intersections in right next to each other. 
			//But what if the intersections are not all perfectly associated with the brick number?
			//For example, say that we intersect with brick [2]. Will this necssarily be the third ( index 2 ) intersection?
			//This is why the intersections also store an "id" value. This id value corresponds to the brick associated with the given intersection. 

			numIntersections++;
		}
	}

	// Ensure that some brick was hit by the ray
	if (numIntersections == 0)
	{
		Result[id.xy] = float4(0, 0, 0, 1);
		return;
	}

	// Sort the bricks by smallest nearT
	insertionSort(intersections, numIntersections);

	// Initialize variables to keep track of the current brick being considered

	int currentBrickIndex = 0;//Does this actually correspond with the current brick in question?

	MetaBrick currentBrick = _MetaBrickBuffer[intersections[currentBrickIndex].id];
	//MetaBrick currentBrick = _MetaBrickBuffer[currentBrickIndex];

	//currentBrick.currentZLevel = 12; 

	MetaVolume currentVolume = _MetaVolumeBuffer[0];

	// Set up ray marching variables/vectors
	float3 vol_ray_pos = ray.origin + (ray.direction * intersections[currentBrickIndex].tNear);	// ray start position in volume space
	
	float3 brick_ray_pos = vol_ray_pos - currentBrick.boxMin;									// ray start position in the current brick's space. This is never even used. 
	float3 ray_step = normalize(ray.direction) * sqrt(3) / _Steps;								// the size of each step when ray marching

	// Ray marching loop
	float4 fColor = 0;
	for (int k = 0; k < _Steps; k++)
	{
		
		// Get the isovalue at the current position
		float isovalue = sampleIntensity(vol_ray_pos, currentBrick, currentVolume.isHz, currentVolume.numBits);

		// Transform this isovalue into the corresponding RGBA color value
		//float4 sampleColor = (currentBrickIndex < 1 ? sampleTransferFunction(isovalue, currentVolume.numBits) : float4(2,0.975, 0.0025, 1));
		//float4 sampleColor = (currentBrick.id == 0 ? sampleTransferFunction(isovalue, currentVolume.numBits) : float4(1, 1, 0, 0.01));
		float4 sampleColor = sampleTransferFunction(isovalue, currentVolume.numBits);
		

		// Front to back blending function
		fColor.rgb = fColor.rgb + (1 - fColor.a) * sampleColor.a * sampleColor.rgb;
		fColor.a = fColor.a + (1 - fColor.a) * sampleColor.a;

		// March along the ray
		vol_ray_pos += ray_step;
		brick_ray_pos += ray_step;

		

		// Check if we have marched out of the volume
		if (vol_ray_pos.x < currentVolume.boxMin.x || vol_ray_pos.y < currentVolume.boxMin.y || vol_ray_pos.z < currentVolume.boxMin.z
			|| vol_ray_pos.x > currentVolume.boxMax.x || vol_ray_pos.y > currentVolume.boxMax.y || vol_ray_pos.z > currentVolume.boxMax.z)
		{
			break;
		}

		// Check if we have marched out of the current brick
		if (vol_ray_pos.x < currentBrick.boxMin.x || vol_ray_pos.y < currentBrick.boxMin.y || vol_ray_pos.z < currentBrick.boxMin.z
			|| vol_ray_pos.x > currentBrick.boxMax.x || vol_ray_pos.y > currentBrick.boxMax.y || vol_ray_pos.z > currentBrick.boxMax.z)
		{

		/* This needs to be numIntersections-1. Otherwise you will increment to a currentBrickIndex one above the actual index of the "last" (deepest) intersection. 
		* If you do not do numIntersections-1, you end up reading in garbage on the boundaries. 
		*/
			if (currentBrickIndex < numIntersections - 1)
			{
				currentBrickIndex++;//This needs to be less than numIntersections at all times. 
				currentBrick = _MetaBrickBuffer[intersections[currentBrickIndex].id];
				
			}
			else
				break;
		}

		


		// If alpha is completely saturated for this pixel, stop ray-marching.
		if (fColor.a > 1.0) 
			break;
	}

	Result[id.xy] = fColor * _NormPerRay;
}
